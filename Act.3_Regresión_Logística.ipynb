{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "4e129374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "73b7ce2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Villa Dante</td>\n",
       "      <td>Dentro de Villa un estudio de arte con futon, ...</td>\n",
       "      <td>Santa Fe Shopping Mall, Interlomas Park and th...</td>\n",
       "      <td>Dici</td>\n",
       "      <td>2010-06-28</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>Master in visual arts, film photography &amp; Mark...</td>\n",
       "      <td>Within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.751745</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.840647</td>\n",
       "      <td>4.713399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Condesa Haus</td>\n",
       "      <td>A new concept of hosting in mexico through a b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fernando</td>\n",
       "      <td>2010-08-09</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>Condesa Haus Rentals  offers independent  stud...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>Condesa</td>\n",
       "      <td>...</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>4.470000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great space in historical San Rafael</td>\n",
       "      <td>This great apartment is located in one of the ...</td>\n",
       "      <td>Very traditional neighborhood with all service...</td>\n",
       "      <td>Maris</td>\n",
       "      <td>2010-10-19</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>I am a University Professor now retired after ...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>San Rafael</td>\n",
       "      <td>...</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>4.790000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 bedroom apt. deco bldg, Condesa</td>\n",
       "      <td>Comfortably furnished, sunny, 2 bedroom apt., ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicholas</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>I am a journalist writing about food, (book an...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>Hipódromo</td>\n",
       "      <td>...</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful light Studio Coyoacan- full equipped !</td>\n",
       "      <td>COYOACAN designer studio quiet &amp; safe! well eq...</td>\n",
       "      <td>Coyoacan is a beautiful neighborhood famous fo...</td>\n",
       "      <td>Trisha</td>\n",
       "      <td>2010-08-24</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>I am a mother, documentary film maker and phot...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>t</td>\n",
       "      <td>Coyoacán</td>\n",
       "      <td>...</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>4.920000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0                                       Villa Dante   \n",
       "1                                      Condesa Haus   \n",
       "2              Great space in historical San Rafael   \n",
       "3                 2 bedroom apt. deco bldg, Condesa   \n",
       "4  Beautiful light Studio Coyoacan- full equipped !   \n",
       "\n",
       "                                         description  \\\n",
       "0  Dentro de Villa un estudio de arte con futon, ...   \n",
       "1  A new concept of hosting in mexico through a b...   \n",
       "2  This great apartment is located in one of the ...   \n",
       "3  Comfortably furnished, sunny, 2 bedroom apt., ...   \n",
       "4  COYOACAN designer studio quiet & safe! well eq...   \n",
       "\n",
       "                               neighborhood_overview host_name  host_since  \\\n",
       "0  Santa Fe Shopping Mall, Interlomas Park and th...      Dici  2010-06-28   \n",
       "1                                                NaN  Fernando  2010-08-09   \n",
       "2  Very traditional neighborhood with all service...     Maris  2010-10-19   \n",
       "3                                                NaN  Nicholas  2011-01-04   \n",
       "4  Coyoacan is a beautiful neighborhood famous fo...    Trisha  2010-08-24   \n",
       "\n",
       "         host_location                                         host_about  \\\n",
       "0  Mexico City, Mexico  Master in visual arts, film photography & Mark...   \n",
       "1  Mexico City, Mexico  Condesa Haus Rentals  offers independent  stud...   \n",
       "2  Mexico City, Mexico  I am a University Professor now retired after ...   \n",
       "3  Mexico City, Mexico  I am a journalist writing about food, (book an...   \n",
       "4  Mexico City, Mexico  I am a mother, documentary film maker and phot...   \n",
       "\n",
       "   host_response_time host_is_superhost host_neighbourhood  ...  \\\n",
       "0      Within an hour                 f                NaN  ...   \n",
       "1      within an hour                 f            Condesa  ...   \n",
       "2  within a few hours                 f         San Rafael  ...   \n",
       "3  within a few hours                 f          Hipódromo  ...   \n",
       "4  within a few hours                 t           Coyoacán  ...   \n",
       "\n",
       "   review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                   4.751745                   4.92   \n",
       "1                   4.700000                   4.87   \n",
       "2                   4.880000                   4.98   \n",
       "3                   4.760000                   4.94   \n",
       "4                   4.960000                   4.96   \n",
       "\n",
       "  review_scores_communication review_scores_location review_scores_value  \\\n",
       "0                        4.92               4.840647            4.713399   \n",
       "1                        4.78               4.980000            4.470000   \n",
       "2                        4.94               4.760000            4.790000   \n",
       "3                        4.92               4.980000            4.920000   \n",
       "4                        4.98               4.960000            4.920000   \n",
       "\n",
       "  calculated_host_listings_count calculated_host_listings_count_entire_homes  \\\n",
       "0                            1.0                                         1.0   \n",
       "1                            9.0                                         4.0   \n",
       "2                            1.0                                         1.0   \n",
       "3                            2.0                                         2.0   \n",
       "4                            3.0                                         2.0   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                          0.0   \n",
       "1                                          2.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          1.0   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                         0.0               0.0  \n",
       "1                                         0.0               0.0  \n",
       "2                                         0.0               0.0  \n",
       "3                                         0.0               0.0  \n",
       "4                                         0.0               1.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar archivo csv\n",
    "df= pd.read_csv(\"BASE.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "6f4eca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['neighborhood_overview', 'host_about', 'host_neighbourhood',\n",
       "       'first_review', 'last_review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "08fed2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_neighbourhood       48.600432\n",
       "neighborhood_overview    47.085338\n",
       "host_about               42.562782\n",
       "first_review             12.776031\n",
       "last_review              12.776031\n",
       "dtype: float64"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isnull().mean() * 100).sort_values(ascending=False).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "072edec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9j/wm9ykq0j7ql95x8sql60c0680000gn/T/ipykernel_4189/1655763348.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df =df.fillna(method=\"bfill\")\n",
      "/var/folders/9j/wm9ykq0j7ql95x8sql60c0680000gn/T/ipykernel_4189/1655763348.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df =df.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "#Rellenamos nulos\n",
    "df =df.fillna(method=\"bfill\")\n",
    "df =df.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "f789f525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'instant_bookable']"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicotomicas = [col for col in df.columns if df[col].nunique() == 2]\n",
    "dicotomicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "246d80d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_is_superhost': array(['f', 't'], dtype=object),\n",
       " 'host_has_profile_pic': array(['t', 'f'], dtype=object),\n",
       " 'host_identity_verified': array(['t', 'f'], dtype=object),\n",
       " 'instant_bookable': array(['f', 't'], dtype=object)}"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{col: df[col].unique() for col in dicotomicas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "3e0933f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_availability\n",
       "t    26401\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"has_availability\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "20ff5c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_is_superhost': array(['f', 't'], dtype=object),\n",
       " 'host_has_profile_pic': array(['t', 'f'], dtype=object),\n",
       " 'host_identity_verified': array(['t', 'f'], dtype=object),\n",
       " 'instant_bookable': array(['f', 't'], dtype=object)}"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{col: df[col].unique() for col in dicotomicas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "9a8ac4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'description', 'neighborhood_overview', 'host_name',\n",
       "       'host_since', 'host_location', 'host_about', 'host_response_time',\n",
       "       'host_is_superhost', 'host_neighbourhood', 'host_listings_count',\n",
       "       'host_total_listings_count', 'host_has_profile_pic',\n",
       "       'host_identity_verified', 'neighbourhood_cleansed', 'property_type',\n",
       "       'room_type', 'amenities', 'has_availability', 'first_review',\n",
       "       'last_review', 'instant_bookable', 'host_id', 'latitude', 'longitude',\n",
       "       'host_response_rate', 'host_acceptance_rate', 'accommodates',\n",
       "       'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights',\n",
       "       'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
       "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
       "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'availability_30',\n",
       "       'availability_60', 'availability_90', 'availability_365',\n",
       "       'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
       "       'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d',\n",
       "       'estimated_revenue_l365d', 'review_scores_rating',\n",
       "       'review_scores_accuracy', 'review_scores_cleanliness',\n",
       "       'review_scores_checkin', 'review_scores_communication',\n",
       "       'review_scores_location', 'review_scores_value',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00276f",
   "metadata": {},
   "source": [
    "PRIMERAS CUATRO VARIABLES:\n",
    "\n",
    "Son dicotómicas \n",
    "\n",
    "1era y 4ta se les aplicó regresión logística sin métodos de reponderación\n",
    "\n",
    "2da y 3era se les aplicó método de oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb077202",
   "metadata": {},
   "source": [
    "1er CASO: Host is superhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "6ef65907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost\n",
       "f    16185\n",
       "t    10216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_is_superhost\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "ee5f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_is_superhost\"] = df[\"host_is_superhost\"].map({'t': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "7c8cf8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4023  887]\n",
      " [1619 1392]]\n"
     ]
    }
   ],
   "source": [
    "df.corr(numeric_only=True)[\"host_is_superhost\"].abs().sort_values(ascending=False).head(11)\n",
    "\n",
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['estimated_occupancy_l365d', 'number_of_reviews_ltm', 'number_of_reviews_ly']]\n",
    "Var_Dep= df['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "2a712b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.7130450194966323\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "c13310ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.6107942079859587\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "c2b5e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.6836258048226234\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "4090ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.8193482688391038\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "fd244435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.4623048820989704\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "ac2458de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.5262759924385634\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=1)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "befb04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.7625094768764216\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=0)\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "b2e28640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_is_superhost'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5890b",
   "metadata": {},
   "source": [
    "2NDO CASO: HOST HAS PROFILE PIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "6edd7c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_has_profile_pic\n",
       "t    25838\n",
       "f      563\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_has_profile_pic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "fc8e7550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_has_profile_pic                           1.000000\n",
       "host_id                                        0.216958\n",
       "number_of_reviews                              0.088765\n",
       "maximum_maximum_nights                         0.084779\n",
       "maximum_nights_avg_ntm                         0.081304\n",
       "minimum_maximum_nights                         0.076060\n",
       "calculated_host_listings_count                 0.068481\n",
       "calculated_host_listings_count_entire_homes    0.065381\n",
       "number_of_reviews_ly                           0.065310\n",
       "host_is_superhost                              0.064521\n",
       "Name: host_has_profile_pic, dtype: float64"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_has_profile_pic\"] = df[\"host_has_profile_pic\"].map({'t': 1, 'f': 0})\n",
    "df.corr(numeric_only=True)[\"host_has_profile_pic\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "a4ac89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_has_profile_pic\"] = df[\"host_has_profile_pic\"].map({1: 't', 0: 'f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "0c7d33b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[   0  177]\n",
      " [   0 7744]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['number_of_reviews', 'maximum_nights_avg_ntm', 'calculated_host_listings_count']]\n",
    "Var_Dep= df['host_has_profile_pic']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "c6ad82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.977654336573665\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.977654336573665\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "4a5ce112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "9294f16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 134   43]\n",
      " [2858 4886]]\n"
     ]
    }
   ],
   "source": [
    "#Aplicamos la técnica de sobremuestreo (oversampling)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Entrenamos el modelo sobremuestreado\n",
    "algoritmo_Over_sampling = LogisticRegression()\n",
    "algoritmo_Over_sampling.fit(X_resampled, y_resampled)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred_over_sampling = algoritmo_Over_sampling.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred_over_sampling)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "fb0f2a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.9912761209170217\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='t')\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "447052ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.04478609625668449\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='f')\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "57160755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.6337583638429491\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred_over_sampling)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "c51b413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.6309400826446281\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='t')\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "84d5ad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.7570621468926554\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='f')\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "16fbb271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.7710881401404561\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='t')\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "bb587812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje F1 del modelo:\n",
      "0.08456926475228779\n"
     ]
    }
   ],
   "source": [
    "# el puntaje F1 que es una combinación entre la precisión y la sensibilidad, para esto importamos f1_score.\n",
    "#Calculo el Puntaje F1 del modelo\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "puntajef1 = f1_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label='f')\n",
    "print('Puntaje F1 del modelo:')\n",
    "print(puntajef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "b26c1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 't'], dtype=object)"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_has_profile_pic'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da103d9a",
   "metadata": {},
   "source": [
    "CASO 3: HOST IDENTITY VERIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "08dd9465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_identity_verified\n",
       "t    25228\n",
       "f     1173\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_identity_verified\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "7f97dee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_identity_verified       1.000000\n",
       "availability_eoy             0.241658\n",
       "availability_365             0.238510\n",
       "availability_90              0.226353\n",
       "availability_60              0.204823\n",
       "availability_30              0.170510\n",
       "estimated_occupancy_l365d    0.138322\n",
       "reviews_per_month            0.131971\n",
       "number_of_reviews_ltm        0.131552\n",
       "host_is_superhost            0.122625\n",
       "Name: host_identity_verified, dtype: float64"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_identity_verified\"] = df[\"host_identity_verified\"].map({'t': 1, 'f': 0})\n",
    "df.corr(numeric_only=True)[\"host_identity_verified\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "f055529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_identity_verified\"] = df[\"host_identity_verified\"].map({1: 't', 0: 'f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "4fcf5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[   0  366]\n",
      " [   0 7555]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['availability_eoy', 'availability_365', 'availability_90']]\n",
    "Var_Dep= df['host_identity_verified']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "80b30fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.953793712915036\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.953793712915036\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "97e59e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 252  114]\n",
      " [1851 5704]]\n"
     ]
    }
   ],
   "source": [
    "#Aplicamos la técnica de sobremuestreo (oversampling)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Entrenamos el modelo sobremuestreado\n",
    "algoritmo_Over_sampling = LogisticRegression()\n",
    "algoritmo_Over_sampling.fit(X_resampled, y_resampled)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred_over_sampling = algoritmo_Over_sampling.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred_over_sampling)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "97c24966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.9804056376761774\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "43152f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.11982881597717546\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "acd9529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.7519252619618735\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred_over_sampling)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "1c211316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.7549966909331568\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "bb48a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.6885245901639344\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred_over_sampling, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5027d",
   "metadata": {},
   "source": [
    "CASO 4: INSTANT BOOKABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "7875c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant_bookable\n",
       "f    15697\n",
       "t    10704\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"instant_bookable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "e9c2a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant_bookable                               1.000000\n",
       "host_acceptance_rate                           0.277075\n",
       "calculated_host_listings_count                 0.276078\n",
       "calculated_host_listings_count_entire_homes    0.212413\n",
       "minimum_nights                                 0.206624\n",
       "minimum_minimum_nights                         0.194622\n",
       "availability_365                               0.181300\n",
       "maximum_maximum_nights                         0.167875\n",
       "host_id                                        0.166093\n",
       "review_scores_communication                    0.159295\n",
       "Name: instant_bookable, dtype: float64"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"instant_bookable\"] = df[\"instant_bookable\"].map({'t': 1, 'f': 0})\n",
    "df.corr(numeric_only=True)[\"instant_bookable\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "3dea9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"instant_bookable\"] = df[\"instant_bookable\"].map({1: 't', 0: 'f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "21d91766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3911  843]\n",
      " [1406 1761]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['host_acceptance_rate', 'calculated_host_listings_count', 'minimum_nights']]\n",
    "Var_Dep= df['instant_bookable']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "30d824b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.6762672811059908\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "cf759b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.7355651683280046\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "4cb0430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo:\n",
      "0.7160712031309178\n"
     ]
    }
   ],
   "source": [
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "2cd200d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.5560467319229555\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "648153a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo:\n",
      "0.822675641564998\n"
     ]
    }
   ],
   "source": [
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119bbbb4",
   "metadata": {},
   "source": [
    "CASO 5: ROOM_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "5c94ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type\n",
       "Entire home/apt    17235\n",
       "Private room        8867\n",
       "Shared room          208\n",
       "Hotel room            91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "d480f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Hotel room', 'Private room', 'Shared room'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['room_type'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "de687f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos una variable categórica a dicotómica \n",
    "df['room_type']= df['room_type'].replace([\"Hotel room\", \"Private room\", \"Shared room\"], \"Rooms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "82ce80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type                                       1.000000\n",
       "calculated_host_listings_count_private_rooms    0.593159\n",
       "accommodates                                    0.497233\n",
       "price                                           0.417819\n",
       "calculated_host_listings_count_entire_homes     0.388821\n",
       "bedrooms                                        0.388738\n",
       "beds                                            0.357622\n",
       "estimated_revenue_l365d                         0.329649\n",
       "reviews_per_month                               0.241554\n",
       "estimated_occupancy_l365d                       0.239028\n",
       "Name: room_type, dtype: float64"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"room_type\"] = df[\"room_type\"].map({'Entire home/apt': 1, 'Rooms': 0})\n",
    "df.corr(numeric_only=True)[\"room_type\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "386a9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"room_type\"] = df[\"room_type\"].map({1: 'Entire home/apt', 0: 'Rooms'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "a85434bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4350  864]\n",
      " [ 661 2046]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['accommodates', 'price', 'bedrooms']]\n",
    "Var_Dep= df['room_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "00e5cdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type\n",
       "Entire home/apt    17235\n",
       "Rooms               9166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "4a737a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.8680902015565756\n",
      "Precisión del modelo:\n",
      "0.7030927835051546\n",
      "Exactitud del modelo:\n",
      "0.8074738038126499\n",
      "Sensibilidad del modelo:\n",
      "0.8342922899884925\n",
      "Sensibilidad del modelo:\n",
      "0.7558182489841152\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Rooms\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Rooms\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45520678",
   "metadata": {},
   "source": [
    "CASO 6: PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "79b37ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  66.,   68.,   92., ..., 3087., 3088., 3089.], shape=(2671,))"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['price'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "f206bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(66.0), np.float64(3089.0)]"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df['price'].max()\n",
    "Min=df['price'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "36b5ccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  65. , 1576.5, 3088. ])"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(65, 3088, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "911c3d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"Precios medios\", \"Precios altos\"]\n",
    "\n",
    "# Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['price']=pd.cut(x= df['price'], bins=intervalos, labels= categorias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "165c57f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price\n",
       "Precios medios    22017\n",
       "Precios altos      4382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "9868e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].map({'Precios medios': 1, 'Precios altos': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "36a5dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['host_is_superhost', 'host_listings_count', 'host_total_listings_count',\n",
      "       'host_id', 'latitude', 'longitude', 'host_response_rate',\n",
      "       'host_acceptance_rate', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
      "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
      "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
      "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
      "       'maximum_nights_avg_ntm', 'availability_30', 'availability_60',\n",
      "       'availability_90', 'availability_365', 'number_of_reviews',\n",
      "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy',\n",
      "       'number_of_reviews_ly', 'estimated_occupancy_l365d',\n",
      "       'estimated_revenue_l365d', 'review_scores_rating',\n",
      "       'review_scores_accuracy', 'review_scores_cleanliness',\n",
      "       'review_scores_checkin', 'review_scores_communication',\n",
      "       'review_scores_location', 'review_scores_value',\n",
      "       'calculated_host_listings_count',\n",
      "       'calculated_host_listings_count_entire_homes',\n",
      "       'calculated_host_listings_count_private_rooms',\n",
      "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.corr(numeric_only=True).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "8bdb7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: price, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/9j/wm9ykq0j7ql95x8sql60c0680000gn/T/ipykernel_4189/241186245.py:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  .str.replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Limpieza + conversión a float\n",
    "df['price'] = (\n",
    "    df['price']\n",
    "    .astype(str)\n",
    "    .str.replace('[\\$,]', '', regex=True)\n",
    "    .str.strip()\n",
    "    .replace('', np.nan)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(df['price'].dtype)\n",
    "print(df['price'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "d690389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: price, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/9j/wm9ykq0j7ql95x8sql60c0680000gn/T/ipykernel_4189/241186245.py:5: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  .str.replace('[\\$,]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Limpieza + conversión a float\n",
    "df['price'] = (\n",
    "    df['price']\n",
    "    .astype(str)\n",
    "    .str.replace('[\\$,]', '', regex=True)\n",
    "    .str.strip()\n",
    "    .replace('', np.nan)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(df['price'].dtype)\n",
    "print(df['price'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "7c096de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                                           1.000000\n",
       "bathrooms                                       0.272580\n",
       "accommodates                                    0.245115\n",
       "bedrooms                                        0.237353\n",
       "beds                                            0.212549\n",
       "calculated_host_listings_count_private_rooms    0.152329\n",
       "calculated_host_listings_count_entire_homes     0.140602\n",
       "longitude                                       0.117182\n",
       "estimated_revenue_l365d                         0.114118\n",
       "host_total_listings_count                       0.112688\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(numeric_only=True)[\"price\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "e819e6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].isna().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "b5abe508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "830d722b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price\n",
       "1.0    22019\n",
       "0.0     4382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "ea732b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].astype(int).map({1: 'Precios medios', 0: 'Precios altos'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "527fbf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[  71 1282]\n",
      " [  65 6503]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['bathrooms', 'accommodates', 'bedrooms']]\n",
    "Var_Dep= df['price']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "d8679541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.8353243416827232\n",
      "Precisión del modelo:\n",
      "0.5220588235294118\n",
      "Exactitud del modelo:\n",
      "0.8299457139250095\n",
      "Sensibilidad del modelo:\n",
      "0.9901035322777101\n",
      "Sensibilidad del modelo:\n",
      "0.0524759793052476\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Precios medios\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Precios altos\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Precios medios\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Precios altos\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f252d",
   "metadata": {},
   "source": [
    "CASO 7: HOST LISTINGS COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "966f4375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  49.,  50.,  51.,  52.,  55.,  56.,  57.,  58.,\n",
       "        59.,  60.,  62.,  65.,  66.,  68.,  73.,  76.,  78.,  82.,  83.,\n",
       "        90.,  91.,  97.,  98., 102., 103., 104., 113., 131., 135., 138.,\n",
       "       161., 178., 236., 246., 250., 258., 284., 398., 417., 442., 513.,\n",
       "       896.])"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_listings_count'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "4adb0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(896.0)]"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df['host_listings_count'].max()\n",
    "Min=df['host_listings_count'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "b9298187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1., 448., 897.])"
      ]
     },
     "execution_count": 987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(-1, 897, 3)\n",
    "intervalos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "8e387fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"Pocas propiedades\", \"Muchas propiedades\"]\n",
    "\n",
    "# Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['host_listings_count']=pd.cut(x= df['host_listings_count'], bins=intervalos, labels= categorias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "22040b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_listings_count\n",
       "Pocas propiedades     26258\n",
       "Muchas propiedades      143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['host_listings_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "7c62fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[  45    1]\n",
      " [   2 7873]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['host_total_listings_count', 'estimated_revenue_l365d', 'minimum_nights_avg_ntm']]\n",
    "Var_Dep= df['host_listings_count']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "8fb2b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.9998729997459995\n",
      "Precisión del modelo:\n",
      "0.9574468085106383\n",
      "Exactitud del modelo:\n",
      "0.9996212599419265\n",
      "Sensibilidad del modelo:\n",
      "0.9997460317460317\n",
      "Sensibilidad del modelo:\n",
      "0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas propiedades\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas propiedades\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas propiedades\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas propiedades\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce325b",
   "metadata": {},
   "source": [
    "CASO 8: HOST RESPONSE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "2dec069d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_response_time\n",
       "within an hour        21547\n",
       "within a few hours     2390\n",
       "within a day           1293\n",
       "a few days or more     1170\n",
       "Within an hour            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_response_time\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "97168eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_time'] = df['host_response_time'].replace({'within an hour': 'Within an hour'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "3620a60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Within an hour', 'a few days or more', 'within a day',\n",
       "       'within a few hours'], dtype=object)"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_response_time'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "7e40532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos una variable categórica a dicotómica \n",
    "df['host_response_time']= df['host_response_time'].replace([\"a few days or more\", \"within a day\", \"within a few hours\"], \"More than an hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "9aca09ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_response_time                             1.000000\n",
       "host_response_rate                             0.467341\n",
       "host_acceptance_rate                           0.420189\n",
       "estimated_occupancy_l365d                      0.217885\n",
       "reviews_per_month                              0.215385\n",
       "number_of_reviews_ltm                          0.204243\n",
       "host_is_superhost                              0.186501\n",
       "calculated_host_listings_count_entire_homes    0.177127\n",
       "number_of_reviews_ly                           0.174384\n",
       "estimated_revenue_l365d                        0.165234\n",
       "Name: host_response_time, dtype: float64"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_response_time\"] = df[\"host_response_time\"].map({'Within an hour': 1, 'More than an hour': 0})\n",
    "df.corr(numeric_only=True)[\"host_response_time\"].abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "d91b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_response_time\"] = df[\"host_response_time\"].map({1.0: 'Within an hour', 0.0: 'More than an hour'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "1a711461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 507  940]\n",
      " [ 154 6320]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['host_response_rate', 'host_acceptance_rate', 'estimated_occupancy_l365d']]\n",
    "Var_Dep= df['host_response_time']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "3b92ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.8705234159779615\n",
      "Precisión del modelo:\n",
      "0.7670196671709532\n",
      "Exactitud del modelo:\n",
      "0.861886125489206\n",
      "Sensibilidad del modelo:\n",
      "0.9762125424776027\n",
      "Sensibilidad del modelo:\n",
      "0.35038009675190046\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Within an hour\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"More than an hour\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Within an hour\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"More than an hour\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d7566",
   "metadata": {},
   "source": [
    "CASO 9 : ACCOMODATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "71590b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0), np.float64(7.0)]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df['accommodates'].max()\n",
    "Min=df['accommodates'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "6acdfb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. ,  3.5,  8. ])"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(-1, 8, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "25dca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"Pocas amenidades\", \"Muchas amenidades\"]\n",
    "\n",
    "# Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['accommodates']=pd.cut(x= df['accommodates'], bins=intervalos, labels= categorias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "479fd351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accommodates\n",
       "Pocas amenidades     17269\n",
       "Muchas amenidades     9132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['accommodates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "20f56567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['accommodates'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "d4626954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2004  790]\n",
      " [ 411 4716]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['bedrooms', 'beds', 'bathrooms']]\n",
    "Var_Dep= df['accommodates']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "7e71150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.8565201598256448\n",
      "Precisión del modelo:\n",
      "0.8298136645962733\n",
      "Exactitud del modelo:\n",
      "0.8483777300845853\n",
      "Sensibilidad del modelo:\n",
      "0.919836161497952\n",
      "Sensibilidad del modelo:\n",
      "0.7172512526843235\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas amenidades\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas amenidades\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Pocas amenidades\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Muchas amenidades\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe0059",
   "metadata": {},
   "source": [
    "CASO 10: MINIMUM NIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "02e1f389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.6, 2. , 3. ])"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['minimum_nights'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "id": "7a058595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0), np.float64(3.0)]"
      ]
     },
     "execution_count": 1008,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df['minimum_nights'].max()\n",
    "Min=df['minimum_nights'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "82fd0d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 4.])"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 4, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "88704430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"0-2 NOCHES\", \"3-4 NOCHES\"]\n",
    "\n",
    "# Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['minimum_nights']=pd.cut(x= df['minimum_nights'], bins=intervalos, labels= categorias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "a464fca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minimum_nights\n",
       "0-2 NOCHES    23574\n",
       "3-4 NOCHES     2827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1011,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['minimum_nights'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "eddb9e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[7019   46]\n",
      " [ 130  726]]\n"
     ]
    }
   ],
   "source": [
    "    #Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df[['minimum_minimum_nights', 'calculated_host_listings_count', 'availability_30']]\n",
    "Var_Dep= df['minimum_nights']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =42)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "84ec0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo:\n",
      "0.9818156385508463\n",
      "Precisión del modelo:\n",
      "0.9404145077720207\n",
      "Exactitud del modelo:\n",
      "0.9777805832596894\n",
      "Sensibilidad del modelo:\n",
      "0.9934890304317056\n",
      "Sensibilidad del modelo:\n",
      "0.8481308411214953\n"
     ]
    }
   ],
   "source": [
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"0-2 NOCHES\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"3-4 NOCHES\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"0-2 NOCHES\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"3-4 NOCHES\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
